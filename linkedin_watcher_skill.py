#!/usr/bin/env python3
"""
Personal AI Employee - LinkedIn Watcher Skill
Gold Tier - G-M3: Social Watchers

Purpose: LinkedIn notification/message perception-only watcher
Tier: Gold
Skill ID: G-M3-T04

CRITICAL: PERCEPTION-ONLY. NEVER posts, NEVER replies, NEVER sends messages.
Only creates intake wrappers in Social/Inbox/.
"""

import os
import sys
import json
import argparse
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Optional

# Import PII redaction
try:
    from mcp_helpers import redact_pii
except ImportError:
    import re
    def redact_pii(text: str) -> str:
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        phone_pattern = r'(\+?\d{1,3}[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}'
        text = re.sub(email_pattern, '[EMAIL_REDACTED]', text)
        text = re.sub(phone_pattern, '[PHONE_REDACTED]', text)
        return text


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class LinkedInWatcher:
    """LinkedIn Watcher - Perception-only intake"""

    def __init__(self, config: Dict):
        self.config = config
        self.checkpoint_data = self._load_checkpoint()
        self.created_count = 0
        self.skipped_count = 0
        self.errors = []

    def _load_checkpoint(self) -> Dict:
        checkpoint_path = self.config['checkpoint_path']
        if os.path.exists(checkpoint_path):
            try:
                with open(checkpoint_path, 'r') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Failed to load checkpoint: {e}")
                return {'processed_ids': [], 'last_run': None}
        return {'processed_ids': [], 'last_run': None}

    def _save_checkpoint(self):
        checkpoint_path = self.config['checkpoint_path']
        self.checkpoint_data['last_run'] = datetime.now(timezone.utc).isoformat()

        if len(self.checkpoint_data['processed_ids']) > 500:
            self.checkpoint_data['processed_ids'] = self.checkpoint_data['processed_ids'][-500:]

        try:
            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)
            with open(checkpoint_path, 'w') as f:
                json.dump(self.checkpoint_data, f, indent=2)
        except Exception as e:
            logger.error(f"Failed to save checkpoint: {e}")

    def reset_checkpoint(self):
        self.checkpoint_data = {'processed_ids': [], 'last_run': None}
        self._save_checkpoint()
        print("✓ LinkedIn checkpoint reset")

    def _create_remediation_task(self, title: str, description: str):
        """Create remediation task in Needs_Action/ when MCP fails"""
        try:
            timestamp = datetime.now(timezone.utc).strftime('%Y%m%d-%H%M')
            filename = f"remediation__mcp__linkedin__{timestamp}.md"
            task_path = Path(self.config['base_dir']) / 'Needs_Action' / filename

            task_content = f"""---
id: remediation_linkedin_{timestamp}
type: remediation
source: linkedin_watcher
created_at: {datetime.now(timezone.utc).isoformat()}
priority: high
status: needs_action
---

# MCP Remediation: {title}

**Issue**: {title}
**Source**: LinkedIn Watcher (G-M3)
**Created**: {datetime.now(timezone.utc).isoformat()}

## Problem

{description}

## Suggested Actions

1. Check `.secrets/linkedin_credentials.json` exists and has valid credentials
2. Verify LinkedIn MCP server is running and reachable
3. Review Docs/mcp_linkedin_setup.md for setup instructions
4. Test connection: `python3 brain_mcp_registry_refresh_skill.py --server linkedin --mock`
5. Re-run watcher in mock mode to verify intake wrapper creation works

## References

- Setup Guide: Docs/mcp_linkedin_setup.md
- Credentials Template: .secrets/README.md
- MCP Registry: Logs/mcp_tools_snapshot_linkedin.json

---
**Generated by**: linkedin_watcher_skill.py
**Graceful Degradation**: Watcher continues running despite MCP failure
"""

            task_path.parent.mkdir(parents=True, exist_ok=True)
            task_path.write_text(task_content, encoding='utf-8')

            logger.info(f"Created remediation task: {filename}")
            self._append_log(f"Remediation task created: {title}")

        except Exception as e:
            logger.error(f"Failed to create remediation task: {e}")

    def _append_log(self, message: str):
        log_path = self.config['log_path']
        try:
            os.makedirs(os.path.dirname(log_path), exist_ok=True)
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')
            with open(log_path, 'a', encoding='utf-8') as f:
                f.write(f"[{timestamp}] {message}\n")
        except Exception as e:
            logger.warning(f"Could not write to log: {e}")

    def _create_intake_wrapper(self, item: Dict, dry_run: bool = False) -> Optional[str]:
        try:
            item_id = item['id']
            sender = item.get('sender', 'unknown')
            timestamp = datetime.now(timezone.utc)
            timestamp_str = timestamp.strftime('%Y%m%d-%H%M')

            # Extract username from LinkedIn URL
            sender_safe = sender.split('/')[-1][:20]

            filename = f"inbox__linkedin__{timestamp_str}__{sender_safe}.md"
            output_path = os.path.join(self.config['output_dir'], filename)

            if dry_run:
                print(f"[DRY-RUN] Would create: {filename}")
                return None

            body = item.get('body', '')
            sender_name = item.get('sender_name', sender_safe)
            item_type = item.get('type', 'notification')
            post_id = item.get('post_id', '')
            comment_id = item.get('comment_id', '')
            thread_id = item.get('thread_id', f"linkedin_{sender_safe}")
            is_urgent = item.get('urgent', False)

            # Privacy-safe excerpt
            excerpt = body[:500] if len(body) <= 500 else body[:497] + "..."
            excerpt = redact_pii(excerpt)

            frontmatter = f"""---
id: {item_id}
source: linkedin
received_at: {item.get('timestamp', timestamp.isoformat())}
sender: {sender}
channel: linkedin
thread_id: {thread_id}
excerpt: "{excerpt}"
status: pending
plan_required: {str(is_urgent).lower()}
pii_redacted: true
linkedin_type: {item_type}
post_id: {post_id}
comment_id: {comment_id}
---

# LinkedIn {item_type.title()} - {sender_name}

**⚠️ PERCEPTION-ONLY**: This is an intake wrapper. No LinkedIn actions have been taken.

## Item Details

**From**: {sender_name}
**Profile**: {sender}
**Received**: {item.get('timestamp', timestamp.isoformat())}
**Type**: {item_type}
**Post ID**: {post_id or 'N/A'}
**Comment ID**: {comment_id or 'N/A'}
**Thread**: {thread_id}
**Urgent**: {is_urgent}

## Content

{body}

## Suggested Next Steps

**If actionable (reply/comment/message)**:
1. Create plan using `brain_create_plan` (Gold Tier - G-M4)
2. Request approval via `brain_request_approval`
3. Execute via `brain_execute_social_with_mcp` (LinkedIn action)

**If informational only**:
- Archive to Done/ with summary note

## Privacy Notice

- PII in excerpt redacted for privacy
- Full content preserved above for context
- Never commit to git (covered by .gitignore)

---
**Generated by**: linkedin_watcher
**Watcher Version**: 1.0.0 (Gold Tier - G-M3)
"""

            os.makedirs(self.config['output_dir'], exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(frontmatter)

            logger.info(f"Created intake wrapper: {filename}")
            return output_path

        except Exception as e:
            logger.error(f"Failed to create intake wrapper: {e}")
            self.errors.append(str(e))
            return None

    def _load_mock_items(self) -> List[Dict]:
        fixture_path = self.config['mock_fixture_path']

        if not os.path.exists(fixture_path):
            raise FileNotFoundError(f"Mock fixture not found: {fixture_path}")

        try:
            with open(fixture_path, 'r') as f:
                items = json.load(f)

            if not isinstance(items, list):
                raise ValueError("Mock fixture must be a JSON array")

            logger.info(f"Loaded {len(items)} mock LinkedIn items")
            return items

        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in mock fixture: {e}")

    def _fetch_items_real(self) -> List[Dict]:
        """
        Fetch notifications from real LinkedIn MCP using QUERY tools only.

        IMPORTANT: This ONLY calls QUERY tools (list_notifications, get_post_analytics).
        NEVER calls ACTION tools (create_post, reply_comment, send_message).

        Returns:
            List of notification dicts in standard format
        """
        try:
            # TODO: Real MCP client integration (G-M4)
            # For now, check if MCP credentials exist
            secrets_path = Path(__file__).parent / '.secrets' / 'linkedin_credentials.json'

            if not secrets_path.exists():
                logger.warning("LinkedIn MCP credentials not found at .secrets/linkedin_credentials.json")
                self._create_remediation_task(
                    "LinkedIn MCP credentials missing",
                    "MCP mode requested but credentials not configured. See Docs/mcp_linkedin_setup.md"
                )
                return []

            # TODO: When MCP client is integrated:
            # 1. Load credentials from secrets_path
            # 2. Initialize MCP client
            # 3. Call linkedin.list_notifications (QUERY tool, no side effects)
            # 4. Transform to standard notification format
            # 5. Return notifications

            logger.info("LinkedIn MCP query tools integration pending (G-M4)")
            logger.info("Use --mode mock for testing until MCP servers are configured")
            return []

        except Exception as e:
            logger.error(f"Failed to fetch from LinkedIn MCP: {e}")
            self._create_remediation_task(
                "LinkedIn MCP query failed",
                f"Error: {e}\nCheck MCP server status and credentials."
            )
            return []

    def run(self, dry_run: bool = False, mock: bool = True, verbose: bool = False) -> Dict:
        start_time = datetime.now(timezone.utc)

        if verbose:
            logger.setLevel(logging.DEBUG)

        logger.info(f"Starting LinkedIn watcher (mock={mock}, dry_run={dry_run})")

        if mock:
            try:
                items = self._load_mock_items()
            except Exception as e:
                logger.error(f"Failed to load mock items: {e}")
                return {'success': False, 'error': str(e)}
        else:
            items = self._fetch_items_real()

        max_results = self.config.get('max_results', 10)
        items = items[:max_results]

        logger.info(f"Processing {len(items)} LinkedIn items")

        for item in items:
            item_id = item.get('id')

            if not item_id:
                logger.warning("Item missing ID, skipping")
                continue

            if item_id in self.checkpoint_data['processed_ids']:
                logger.debug(f"Skipping already processed: {item_id}")
                self.skipped_count += 1
                continue

            output_path = self._create_intake_wrapper(item, dry_run=dry_run)

            if output_path:
                self.created_count += 1
                if not dry_run:
                    self.checkpoint_data['processed_ids'].append(item_id)

        if not dry_run and self.created_count > 0:
            self._save_checkpoint()

        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        summary = (
            f"LinkedIn watcher complete: "
            f"{len(items)} scanned, {self.created_count} created, "
            f"{self.skipped_count} skipped, {len(self.errors)} errors, "
            f"{duration:.2f}s"
        )

        self._append_log(summary)

        try:
            with open('system_log.md', 'a', encoding='utf-8') as f:
                f.write(f"\n**[{start_time.isoformat()}]** {summary}\n")
        except:
            pass

        print(f"\n✅ {summary}")

        return {
            'success': True,
            'scanned': len(items),
            'created': self.created_count,
            'skipped': self.skipped_count,
            'errors': len(self.errors),
            'duration': duration
        }


def main():
    parser = argparse.ArgumentParser(description='LinkedIn Watcher - Perception-only (Gold Tier - G-M4)')
    parser.add_argument('--once', action='store_true', default=True, help='Run once and exit (default)')
    parser.add_argument('--dry-run', action='store_true', help='Simulate run without creating files')
    parser.add_argument('--mode', type=str, choices=['mock', 'mcp'], default='mock',
                        help='Data source mode: mock (default, uses templates/mock_linkedin.json) or mcp (uses LinkedIn MCP QUERY tools)')
    parser.add_argument('--max-results', type=int, default=10, help='Maximum items to process (default: 10)')
    parser.add_argument('--reset-checkpoint', action='store_true', help='Reset checkpoint before running')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose logging')

    args = parser.parse_args()

    # Determine mock vs MCP mode
    use_mock = (args.mode == 'mock')

    config = {
        'base_dir': Path(__file__).parent,
        'checkpoint_path': 'Logs/linkedin_watcher_checkpoint.json',
        'log_path': 'Logs/linkedin_watcher.log',
        'output_dir': 'Social/Inbox',
        'max_results': args.max_results,
        'mock_fixture_path': 'templates/mock_linkedin.json'
    }

    watcher = LinkedInWatcher(config)

    if args.reset_checkpoint:
        watcher.reset_checkpoint()

    result = watcher.run(dry_run=args.dry_run, mock=use_mock, verbose=args.verbose)

    return 0 if result['success'] else 1


if __name__ == "__main__":
    sys.exit(main())
